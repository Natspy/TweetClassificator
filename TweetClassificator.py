# -*- coding: utf-8 -*-
"""NK_zadanie_02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xZhbFXV30aSQzHPxRjOzsEPdWdsdS45w

# Praca domowa I, zadanie II

## Tre

### Wstp fabularny

Wyobra藕 sobie, 偶e jeste pracownikiem w firmie sprzedajcej kompleksow usug tworzenia wizerunk贸w medialnych. Oddzia, w kt贸rym pracujesz obsuguje wa偶nego klienta dziaajcego w bran偶y gier i usug cyfrowych.

Twoim zadaniem jest przygotowa model uczenia maszynowego, kt贸ry okrela bdzie nastawienie emocjonalne post贸w z Twittera. Zesp贸 odpowiadajcy za zbieranie danych wanie dostarczy zestaw danych dla Ciebie.

Do tej pory klasyfikowaniem nastroj贸w z twitt贸w zajmowa si zesp贸 ekspert贸w. Rozwizanie takie jest bardzo wolne i drogie, a dokadno ekspert贸w wynosi tylko 95%. Dlatego zarzd firmy zleci wdro偶enie modelu uczenia maszynowego.

Tw贸j model stanowi bdzie jedynie cz wikszego produktu oferowanego przez Twoj firm. Wyniki Twojego modelu bd bezporednio wykorzystywane przez nastpny zesp贸, kt贸rego zadaniem jest przygotowa kolejny model uczenia maszynowego przewidujcy reakcje opinii publicznej na posty klienta.

Prace zespou, kt贸ry korzysta bdzie z Twojego modelu s ju偶 bardzo zaawansowane, dlatego nie mo偶e on pozwoli sobie na 偶adne dodatkowe zmiany w swoim projekcie. Absolutnie konieczne jest, aby Tw贸j model przyporzdkowywa posty do jednej z trzech klas 'Positive', 'Negative', 'Neutral' lub analogicznych. Posty nie na temat powinny by klasyfikowane jako 'Neutral'.

Notebook z Twoim projektem bdzie oglda Tw贸j szef, wic koniecznie zadbaj, 偶eby znalazy si w nim najwa偶niejsze przemylenia, a rysunki byy adne.

Powodzenia 

### Polecenia

1. Wstpna obr贸bka danych:

 - zaaduj zbi贸r treningowy i testowy,
 - usu wiersze o brakujcych elementach,
 - w kolumnie `sentiment` zamie wartoci `'Irrelevant'` na `'Neutral'`.

1. Wykonaj wizualizacje danych:

 - histogram temat贸w twitt贸w (`entity`),
 - histogram nastawie (`sentiment`),
 - najczciej padajcych s贸w w treci twitt贸w (`content`).

1. Przygotuj dane:

 - przygotuj zbi贸r cech poprzez wektoryzacje kolumny `content`, 
 - przygotuj etykiety poprzez zakodowanie tekstowych wartoci w kolumnie `sentiment` do postaci liczbowej.

  Nastpnie wytrenuj naiwny model bayesowski. Sprawd藕 dziaanie modelu na kilku wasnorcznie napisanych wiadomociach. 

1. Wytrenuj modele:
 - naiwny bayesowski,
 - liniowy SVM,
 - regresji logistycznej,
 - drzewo decyzyjne.

  Sprawd藕 model na danych treningowych (walidacja krzy偶owa) i testowych, nastpnie wybierz najlepszy model. Uzasadnij sw贸j wyb贸r.
  
1. Zesp贸 ekspert贸w rcznie klasyfikuje dane z dokadnoci 95%. Por贸wnaj z nimi sw贸j model i napisz jakie s przewagi Twojego modelu.

### Zbi贸r danych

Zbi贸r danych zosta przygotowany na podstawie zbioru [Twitter Sentiment Analysis](https://www.kaggle.com/jp797498e/twitter-entity-sentiment-analysis) i skada si z dw贸ch plik贸w:
-  `twitter_training.csv` - zbi贸r treningowy,
- `twitter_validation.csv` - zbi贸r testowy.

Archiwum z plikami mo偶na pobra z [dysku google](https://drive.google.com/file/d/1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB/view?usp=sharing) lub odkomentowujc poni偶sze linie:
"""

#! pip install gdown
! gdown https://drive.google.com/uc?id=1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB
! unzip twitter.zip

"""# Rozwizanie - Natalia Karczewska 418376
---

##1. Wstpna obr贸bka danych
---
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns

# Tworzenie obiekt贸w pd.DataFrame na podstawie plik贸w twitter_training.csv oraz twitter_validation.csv

df_train = pd.read_csv("/content/twitter_training.csv", sep=",")
df_test = pd.read_csv("/content/twitter_validation.csv", sep=",")
df_train.head()

df_test.head()

print("Ksztat zbioru treningowego:", df_train.shape)
print("Ksztat zbioru testowego:", df_test.shape)

# Usunicie wierszy zawierajcych wartoci nieokrelone 'NaN'

df_train = df_train.dropna(axis=0)
df_test = df_test.dropna(axis=0)
print("Ksztat zbioru treningowego po usuniciu pustych wierszy:", df_train.shape)
print("Ksztat zbioru testowego po usuniciu pustych wierszy:", df_test.shape)

# Zmiana wartoci 'Irrelevant' na 'Neutral'

df_train['sentiment'] = df_train['sentiment'].replace(['Irrelevant'],'Neutral')
df_test['sentiment'] = df_test['sentiment'].replace(['Irrelevant'],'Neutral')

"""## 2. Wizualizacja danych
---
"""

# Histogram temat贸w tweet贸w (zbi贸r treningowy)
fig = plt.figure(figsize = (30,4))

ax = sns.countplot(x='entity', data=df_train)
ax.set_xticklabels(labels=np.sort(df_train.entity.unique()), rotation=50, ha="right")
plt.ylabel("Liczba wystpie tematu")
plt.grid(True, linestyle='-.', color='grey')
plt.title('Histogram temat贸w twitt贸w (zbi贸r treningowy)')
plt.ylim(0,2800)
plt.show()

# Histogram temat贸w tweet贸w (zbi贸r testowy)
fig = plt.figure(figsize = (30,4))

ax2 = sns.countplot(x='entity', data=df_test)
ax2.set_xticklabels(labels=np.sort(df_test.entity.unique()), rotation=50, ha="right")
plt.ylabel("Liczba wystpie tematu")
plt.grid(True, linestyle='-.', color='grey')
plt.title('Histogram temat贸w twitt贸w (zbi贸r testowy)')
plt.show()

"""#### Obserwacja:
W zbiorze treningowym wikszo temat贸w tweet贸w wystpuje podobnie czsto, w zbiorze testowym obserwuj wiksze zr贸偶nicowanie pod wzgldem wystpie danego tematu.
"""

# Histogramy nastawie tweet贸w
fig = plt.figure(figsize = (12,7))

plt.subplot(1,2,1)
labels, counts = np.unique(df_train['sentiment'], return_counts=True,)
plt.bar(labels, counts, align='center', color="lightskyblue", edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.ylabel("Liczba wystpie tweet贸w o danym nastawieniu")
plt.title("Histogram nastawie tweet贸w (zbi贸r treningowy)")

plt.subplot(1,2,2)
labels, counts = np.unique(df_test['sentiment'], return_counts=True,)
plt.bar(labels, counts, align='center', color="pink", edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.title("Histogram nastawie tweet贸w (zbi贸r testowy)")

plt.show()

"""#### Obserwacja:
Najwicej tweet贸w ma nacechowanie neutralne, natomiast pozytywnych oraz negatywnych tweet贸w wystpuje zbli偶ona ilo, zar贸wno w zbiorze treningowym, jak i w testowym.

#### Analiza czstoci wystpowania s贸w w tweetach za pomoc biblioteki WordCloud

Wielko sowa odpowiada czstoci jego wystpowania w zbiorze danych.
"""

!pip3 install wordcloud
import wordcloud

from wordcloud import WordCloud

fig = plt.figure(figsize = (20,10))
fig.suptitle("Najczciej wystpujce sowa w tweetach (zbi贸r treningowy)", fontsize=20, va='top')

# Sowa z klasyfikacji pozytywnej
plt.subplot(1,2,1)
positive_words = " ".join(list(df_train[df_train['sentiment']=='Positive']['content']))
positive_plot = WordCloud(width = 512, height = 512).generate(positive_words)
plt.title("Tweety pozytywne",fontsize=15)
plt.imshow(positive_plot)

# Sowa z klasyfikacji negatywnej
plt.subplot(1,2,2)
negative_words = " ".join(list(df_train[df_train['sentiment']=='Negative']['content']))
negative_plot = WordCloud(width = 512, height = 512).generate(negative_words)
plt.title("Tweety negatywne",fontsize=15)
plt.imshow(negative_plot)

plt.show()

fig = plt.figure(figsize = (20,10))
fig.suptitle("Najczciej wystpujce sowa w tweetach (zbi贸r testowy)", fontsize=20, va='top')

# Sowa z klasyfikacji pozytywnej
plt.subplot(1,2,1)
positive_words = " ".join(list(df_test[df_test['sentiment']=='Positive']['content']))
positive_plot = WordCloud(width = 512, height = 512).generate(positive_words)
plt.title("Tweety pozytywne",fontsize=15)
plt.imshow(positive_plot)

# Sowa z klasyfikacji negatywnej
plt.subplot(1,2,2)
negative_words = " ".join(list(df_test[df_test['sentiment']=='Negative']['content']))
negative_plot = WordCloud(width = 512, height = 512).generate(negative_words)
plt.title("Tweety negatywne",fontsize=15)
plt.imshow(negative_plot)

plt.show()

"""## 3. Przygotowanie danych do analizy
--- 
"""

# Przygotowanie kolumny etykiet

# Zmiana wartoci 'Positive' na '1'
df_train['sentiment'] = df_train['sentiment'].replace(['Positive'],int(1))
df_test['sentiment'] = df_test['sentiment'].replace(['Positive'],int(1))

# Zmiana wartoci 'Negative' na '0'
df_train['sentiment'] = df_train['sentiment'].replace(['Negative'],int(0))
df_test['sentiment'] = df_test['sentiment'].replace(['Negative'],int(0))

# Zmiana wartoci 'Neutral' na '2'
df_train['sentiment'] = df_train['sentiment'].replace(['Neutral'],int(2))
df_test['sentiment'] = df_test['sentiment'].replace(['Neutral'],int(2))

df_test

"""### Naiwny klasyfikator Bayesa oraz sprawdzenie jego dziaania na kilku wasnorcznie napisanych tweetach"""

# Trenowanie naiwnego modelu bayesowskiego oraz sprawdzenie jego dziaania na kilku wasnorcznie napisanych tweetach

my_test = {'sentiment': [1,1,0,0], 'content': ["Man I love this new champion in League Of Legends, he's dope",
                                               "Red Dead Redemption was the best game i've played this year",
                                               "You still can bug yourself in that wall? Fix that shit yo",
                                               "This fucking game is so full of cheaters that I rage quitted already three times this week"]}
df_my_test = pd.DataFrame(data=my_test)
df_my_test

# Trenowanie naiwnego modelu bayesowskiego
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

X_train = df_train.content
y_train = df_train.sentiment

X_my_test = df_my_test.content
y_my_test = df_my_test.sentiment 

# Wektoryzacja kolumny 'content'
vectorizer = CountVectorizer()

X_train = vectorizer.fit_transform(X_train)
X_my_test = vectorizer.transform(X_my_test)

# Tworzenie obiektu klasyfikatora
clf = MultinomialNB()

# Uczenie klasyfikatora na zbiorze uczcym
clf.fit(X_train, y_train)

# Predykcja dla rcznie napisanych przykad贸w oraz wyniki
y_pred = clf.predict(X_my_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_my_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_my_test, y_pred))

print("-"*55)
print("Accuracy score:")
print(accuracy_score(y_my_test, y_pred))

"""#### Obserwacja:

Model zdaje si dziaa dobrze, ale musi on zosta sprawdzony na wikszej iloci przykad贸w, gdy偶 te napisane przeze mnie s dosy proste (u偶ywam odpowiednich s贸w zaobserwowanych w wizualizacji danych), dodatkowo przykad贸w jest stosunkowo mao.

## 4. Trenowanie modeli uczenia maszynowego
---

### a) Konstrukcja modeli oraz sprawdzenie ich dziaania na zbiorze treningowym (Walidacja krzy偶owa)
"""

# Podzia zbioru treningowego - zestaw testowy stanowi 20% 
from sklearn.model_selection import train_test_split

X = df_train.content
y = df_train.sentiment

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Wektoryzacja kolumny 'content'
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()

X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# Sownik na wyniki (w celu p贸藕niejszego por贸wnania modeli)
d = {}

"""#### Naiwny klasyfikator Bayesa (1)"""

# Tworzenie instancji klasyfikatora Multinomial Naive Bayes
from sklearn.naive_bayes import MultinomialNB

clf = MultinomialNB()

# Uczenie klasyfikatora na zbiorze uczcym
clf.fit(X_train, y_train)

# Predykcja

y_pred = clf.predict(X_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['bayes(1)'] = ACC

"""####Drzewa decyzyjne (1)"""

# Tworzenie instancji klasyfikatora Decision Tree Classifier
from sklearn import tree

clf = tree.DecisionTreeClassifier()

clf.fit(X_train, y_train)

# predykcja dla zbioru testowego oraz miary jakoci
y_pred = clf.predict(X_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['drzewa(1)'] = ACC

"""#### Regresja logistyczna (1)"""

# Tworzenie instancji obiektu klasy LogisticRegression
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

# Trenowanie modelu
model.fit(X_train,y_train)

# predykcja dla zbioru testowego oraz miary jakoci
y_pred = model.predict(X_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['regr(1)'] = ACC

"""#### Algorytm wektor贸w wspierajcych (SVM)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Trening klasyfikatora SVM
# from sklearn.svm import SVC
# 
# # Trenowanie modelu zajmowao troch za dugo, dlatego zmniejszam rozmiar zbioru uczcego
# X = df_train.content[:10000] 
# y = df_train.sentiment[:10000]
# 
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# 
# vectorizer = CountVectorizer()
# X_train = vectorizer.fit_transform(X_train)
# X_test = vectorizer.transform(X_test)
# 
# model = SVC()
# model.fit(X_train,y_train)
# 
# # Predykcja
# y_pred = model.predict(X_test)

# Miary jakoci

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['svm(1)'] = ACC

# Zobaczmy dotychczasowe por贸wnanie dokadnoci modeli
for key in d.keys():
  print(str(key) + ': ACC = ' + str(round(d[key], 3)))

"""#### Obserwacja:
Algorytm wektor贸w wspierajcych jest p贸ki co najlepiej rokujcym modelem, jego dokadno jest o niecae 4% ni偶sza od dokadnoci zespou ekspert贸w rcznie klasyfikujcych dane. Nie da si ukry, 偶e przewag algorytmu nad zespoem ekspert贸w jest znacznie szybszy czas klasyfikacji - a jak wiadomo, czas to pienidz. Model SVM klasyfikuje poprawnie okoo 91% z 2000 przypadk贸w w mniej ni偶 15 sekund.

### b) Konstrukcja modeli oraz sprawdzenie ich dziaania na zbiorze testowym
"""

# Podzia danych na treningowe oraz testowe
X_train = df_train.content
y_train = df_train.sentiment

# Jako zbi贸r testowy wykorzystuj tym razem dane przeznaczone do walidacji z pliku twitter_validation.csv
X_test = df_test.content
y_test = df_test.sentiment

# Wektoryzacja kolumny 'content'
vectorizer = CountVectorizer()

X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

"""#### Naiwny klasyfikator Bayesa (2)"""

# Tworzenie obiektu klasyfikatora
clf = MultinomialNB()

# Uczenie klasyfikatora na zbiorze uczcym
clf.fit(X_train, y_train)

# Predykcja dla przykad贸w ze zbioru testowego
y_pred = clf.predict(X_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['bayes(2)'] = ACC

"""####Drzewa decyzyjne (2)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Tworzenie instancji klasyfikatora Decision Tree Classifier
# 
# clf = tree.DecisionTreeClassifier()
# 
# # Fitowanie
# clf.fit(X_train, y_train)
# 
# # predykcja dla zbioru testowego
# y_pred = clf.predict(X_test)

# Miary jakoci

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['drzewa(2)'] = ACC

"""#### Regresja logistyczna (2)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Tworzenie instancji obiektu klasy LogisticRegression
# model = LogisticRegression(solver='lbfgs')
# 
# # Trenowanie modelu
# model.fit(X_train,y_train)
# 
# # Predykcja dla zbioru testowego
# y_pred = model.predict(X_test)

# Miary jakoci

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['regr(2)'] = ACC

"""#### Algorytm wektor贸w wspierajcych (SVM) (2)"""

# Trening klasyfikatora SVM

X = df_train.content[:10000] # Trenowanie modelu zajmowao troch za dugo, dlatego zmniejszam rozmiar zbioru uczcego
y = df_train.sentiment[:10000]
X_test = df_test.content

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(X)
X_test = vectorizer.transform(X_test)

model = SVC()
model.fit(X, y)

# Tym razem przetestuj model SVM na danych walidacyjnych
y_pred = model.predict(X_test)

print("-"*55)
print("Classification report:")
print(classification_report(y_test, y_pred, zero_division=0))

print("-"*55)
print("Confusion matrix:")
print(confusion_matrix(y_test, y_pred))

print("-"*55)
print("Accuracy score:")
ACC = accuracy_score(y_test, y_pred)
print(ACC)

d['svm(2)'] = ACC

# Zobaczmy por贸wnanie dokadnoci modeli po przetestowaniu ich danymi przeznaczonymi do walidacji
for key in d.keys():
  print(str(key) + ': ACC = ' + str(round(d[key], 3)))

"""#### Obserwacja:
Ostateczna weryfikacja modeli nieco zmienia sytuacj. Algorytm wektor贸w wspierajcych okaza si nie by tak dokadny, jak wczeniej przypuszczano - by mo偶e we wczeniejszym przypadku mielimy do czynienia z przeuczeniem - model osiga dobre wyniki gdy jego dziaanie sprawdzano na danych pochodzcych z tego samego zbioru treningowego, jednak daje on znacznie gorsze wyniki, gdy zastosuje si go do danych, z kt贸rymi nie zetkn si podczas uczenia. Warto jednak zauwa偶y, 偶e w przypadku reszty modeli, metryki polepszyy si znaczco - na prowadzenie wysuwa si regresja logistyczna.

## 5. Podsumowanie i wnioski
---

* Modele uczenia maszynowego przetestowano na dwa sposoby: 
> 1. Zastosowano prost walidacj krzy偶ow przeprowadzon z wykorzystaniem danych treningowych z pliku twitter_training.csv - Zbi贸r danych podzielono na zbi贸r uczcy oraz zbi贸r testowy korzystajc z funkcji *train_test_split()* z moduu *sklearn.model_selection*. Rozmiar zbioru testowego stanowi 20% rozmiaru zbioru uczcego. Modele wytrenowano na zbiorze uczcym, a nastpnie sprawdzono ich dziaanie na zbiorze testowym.
> 2. Dane z pliku twitter_training.csv wykorzystano w caoci jako zbi贸r uczcy, natomiast dane z pliku twitter_validation.csv wykorzystano jako zbi贸r testowy. Ponownie, modele wytrenowano na zbiorze uczcym, natomiast dziaanie modeli sprawdzono na zbiorze testowym, kt贸ry tym razem skada si bezporednio z przykad贸w przeznaczonych do walidacji.

* Poza modelem SVM, wszystkie modele radz sobie lepiej z klasyfikacj testowan sposobem numer 2.

* Zwracajc uwag zar贸wno na metryki modeli jak i na czas potrzebny do wytrenowania oraz zastosowania modelu, zdecydowanie najlepiej prezentuje si model regresji logistycznej. Model potrzebuje niecaych 12 sekund na trening oraz poprawne sklasyfikowanie okoo 94% z 1000 przykad贸w. Dokadno modelu jest niemal偶e tak samo wysoka, jak dokadno ekspert贸w klasyfikujcych dane rcznie. Na drugim miejscu znajduj si drzewa decyzyjne, klasyfikujce dane z dokadnoci okoo 93%, potrzebujce jednak troch du偶szego czasu na trening oraz klasyfikacj (okoo 36s). Zatem wracajc do modelu regresji logistycznej, nale偶y zwr贸ci uwag na to, 偶e rczna klasyfikacja 1000 przykad贸w przez zesp贸 ekspert贸w zajmuje niepor贸wnywalnie wicej czasu, ni偶 12 sekund. Zatem wybrany model nie tylko spisuje si w por贸wnywalny spos贸b pod wzgldem dokadnoci, ale ma on r贸wnie偶 ogromn przewag pod wzgldem czasu potrzebnego na klasyfikacj.
"""